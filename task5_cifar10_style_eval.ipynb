{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images_in_folder(folder_path, size=(32, 32)):\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with Image.open(file_path) as img:\n",
    "                    img = img.resize(size)\n",
    "                    img.save(file_path)\n",
    "\n",
    "resize_images_in_folder('stylized_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from models.model import ResNet50, ViTBase, CLIPModel\n",
    "from models.utils import train_step, eval_step, DataLoaders, CIFAR100_Splits\n",
    "from torch.utils.data import ConcatDataset\n",
    "from models.transforms import transforms_resnet,transforms_clip_vit,transforms_vit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10, CIFAR100, ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Final Train Accuracy: 0.8142\n",
      "Final Train Loss: 0.5575808649096647\n",
      "Final Test Accuracy: 0.2347\n",
      "Final Test Loss: 2.7660347352361985\n"
     ]
    }
   ],
   "source": [
    "train = CIFAR10(root='data', train=True, transform=transforms_resnet, download=True)\n",
    "test = ImageFolder('test2', transform=transforms_resnet)\n",
    "dl = DataLoaders(train,test,'resnet',BATCH_SIZE,True,'cifar10')\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "\n",
    "resnet_model = ResNet50(n_classes=10)\n",
    "resnet_model.load_state_dict(torch.load(\"resnet50_cifar10.pth\")) \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr_loss,tr_acc = eval_step(resnet_model,train_loader,loss_func,device,'resnet','cifar10')\n",
    "ts_loss,ts_acc = eval_step(resnet_model,test_loader,loss_func,device,'resnet','cifar10')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr_acc)\n",
    "print(\"Final Train Loss:\",tr_loss)\n",
    "print(\"Final Test Accuracy:\",ts_acc)\n",
    "print(\"Final Test Loss:\",ts_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Final Train Accuracy: 0.97889996\n",
      "Final Train Loss: 0.06733766217838706\n",
      "Final Test Accuracy: 0.4035\n",
      "Final Test Loss: 2.3011767249198476\n"
     ]
    }
   ],
   "source": [
    "train = CIFAR10(root='data',transform=transforms_vit,download=True)\n",
    "test = ImageFolder('test2', transform=transforms_vit)\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 3\n",
    "dl = DataLoaders(train,test,'vit',BATCH_SIZE,True,'cifar10')\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "vit_model = ViTBase(n_classes=10)\n",
    "vit_model.load_state_dict(torch.load(\"vitbase_cifar10.pth\")) \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr_loss,tr_acc = eval_step(vit_model,train_loader,loss_func,device,'vit','cifar10')\n",
    "ts_loss,ts_acc = eval_step(vit_model,test_loader,loss_func,device,'vit','cifar10')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr_acc)\n",
    "print(\"Final Train Loss:\",tr_loss)\n",
    "print(\"Final Test Accuracy:\",ts_acc)\n",
    "print(\"Final Test Loss:\",ts_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Final Train Accuracy: 0.96632\n",
      "Final Train Loss: 2.243054810279469\n",
      "Final Test Accuracy: 0.34649998\n",
      "Final Test Loss: 61.76155824114563\n"
     ]
    }
   ],
   "source": [
    "train = CIFAR10(root='data',download=True)\n",
    "test = ImageFolder('test2')\n",
    "\n",
    "dl = DataLoaders(train,test,'clip',BATCH_SIZE,True,'cifar10')\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "clip_model =CLIPModel(emb_dim=256)\n",
    "clip_model.load_state_dict(torch.load(\"clip_cifar10.pth\")) \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr_loss,tr_acc = eval_step(clip_model,train_loader,loss_func,device,'clip','cifar10')\n",
    "ts_loss,ts_acc = eval_step(clip_model,test_loader,loss_func,device,'clip','cifar10')\n",
    "\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr_acc)\n",
    "print(\"Final Train Loss:\",tr_loss)\n",
    "print(\"Final Test Accuracy:\",ts_acc)\n",
    "print(\"Final Test Loss:\",ts_loss)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
