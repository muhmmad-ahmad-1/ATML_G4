{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import ResNet50, ViTBase, CLIPModel\n",
    "from models.utils import train_step, eval_step, DataLoaders\n",
    "from models.transforms import transforms_resnet, transforms_vit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up image transformations (adjust as needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize all images to the same size\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n",
    "])\n",
    "\n",
    "# Load dataset from folders\n",
    "train_dataset = datasets.ImageFolder(root='./train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='./texture/cue-conflict', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:09<00:00, 83.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.95375\n",
      "Final Test Accuracy: 0.37625\n",
      "Final Train Loss: 0.35071394562721253\n",
      "Final Test Loss: 1.7723349618911743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and then Evaluate (Three Different Train and Evaluation Loops)\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype, data=\"texture\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"texture\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ResNet50(n_classes=10)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'resnet50')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tr).to_csv(\"resnet50_newdataset_tr_1.csv\") \n",
    "pd.DataFrame(ts).to_csv(\"resnet50_newdataset_ts_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"resnet50_newdataset.pth\")\n",
    "model.load_state_dict(torch.load(\"resnet50_newdataset.pth\"))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import ViTBase\n",
    "from models.utils import train_step, eval_step, DataLoaders\n",
    "from models.transforms import transforms_resnet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up image transformations (adjust as needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to the same size\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n",
    "])\n",
    "\n",
    "# Load dataset from folders\n",
    "train_dataset = datasets.ImageFolder(root='./train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='./texture/cue-conflict', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [15:06<00:00, 453.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.99125\n",
      "Final Test Accuracy: 0.44375\n",
      "Final Train Loss: 0.12436148136854172\n",
      "Final Test Loss: 1.7933626294136047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and then Evaluate (Three Different Train and Evaluation Loops)\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype, data=\"texture\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"texture\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ViTBase(n_classes=10)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'vitbase')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tr).to_csv(\"vitbase_newdataset_tr_1.csv\") \n",
    "pd.DataFrame(ts).to_csv(\"vitbase_newdataset_ts_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"vitbase_newdataset.pth\")\n",
    "model.load_state_dict(torch.load(\"vitbase_newdataset.pth\"))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from folders\n",
    "train_dataset = ImageFolder(root='./train')\n",
    "test_dataset = ImageFolder(root='./texture/cue-conflict')\n",
    "\n",
    "# Create data loaders\n",
    "loader = DataLoaders(train_dataset,test_dataset= test_dataset, batch_size=64, model_type='clip',data='texture',shuffle=True)\n",
    "train_loader, test_loader = loader.get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:12<00:00,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.96625\n",
      "Final Test Accuracy: 0.36124998\n",
      "Final Train Loss: 0.5304164258472156\n",
      "Final Test Loss: 4.328795304665198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and then Evaluate (Three Different Train and Evaluation Loops)\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype, data=\"texture\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"texture\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = CLIPModel(256)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'clip')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tr).to_csv(\"clip_newdataset_tr_1.csv\") \n",
    "pd.DataFrame(ts).to_csv(\"clip_newdataset_ts_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"clip_newdataset.pth\")\n",
    "model.load_state_dict(torch.load(\"clip_newdataset.pth\"))   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
