{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import ResNet18, ResNet50, ViTBase, CLIPModel\n",
    "from models.utils import train_step, eval_step, PACS_dataloaders\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet 50 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['art_painting', 'cartoon','photo','sketch'] \n",
    "results = {domain:{} for domain in domains}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Art Painting Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\PCF\\.conda\\envs\\SProj\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 3/3 [02:05<00:00, 41.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.8688153\n",
      "Final Test Accuracy: 0.6381836\n",
      "Final Train Loss: 0.4416772722005844\n",
      "Final Test Loss: 1.038546584546566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[0]\n",
    "dl = PACS_dataloaders('resnet',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ResNet50(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'resnet50')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cartoon Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:05<00:00, 21.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.8680528\n",
      "Final Test Accuracy: 0.5311433\n",
      "Final Train Loss: 0.44872582480311396\n",
      "Final Test Loss: 1.258961017067368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[1]\n",
    "dl = PACS_dataloaders('resnet',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ResNet50(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'resnet50')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Photo Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:04<00:00, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.8367985\n",
      "Final Test Accuracy: 0.9257485\n",
      "Final Train Loss: 0.5362253068512632\n",
      "Final Test Loss: 0.2655365682310528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[2]\n",
    "dl = PACS_dataloaders('resnet',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ResNet50(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'resnet50')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sketch Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:04<00:00, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9183437\n",
      "Final Test Accuracy: 0.49452785\n",
      "Final Train Loss: 0.3113542125413292\n",
      "Final Test Loss: 1.3661283639169508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[3]\n",
    "dl = PACS_dataloaders('resnet',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ResNet50(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'resnet50')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"PACS_resnet50.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VitBase \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['art_painting', 'cartoon','photo','sketch'] \n",
    "results = {domain:{} for domain in domains}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Art Painting Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\PCF\\.conda\\envs\\SProj\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\PCF\\.conda\\envs\\SProj\\Lib\\site-packages\\timm\\models\\vision_transformer.py:92: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  x = F.scaled_dot_product_attention(\n",
      "100%|██████████| 3/3 [01:55<00:00, 38.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.941332\n",
      "Final Test Accuracy: 0.88671875\n",
      "Final Train Loss: 0.1826369807422161\n",
      "Final Test Loss: 0.3757807007059455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[0]\n",
    "dl = PACS_dataloaders('vit',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ViTBase(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'vit')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cartoon Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:54<00:00, 38.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9530535\n",
      "Final Test Accuracy: 0.77389073\n",
      "Final Train Loss: 0.1517543316508333\n",
      "Final Test Loss: 0.6523539230630204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[1]\n",
    "dl = PACS_dataloaders('vit',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ViTBase(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'vit')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Photo Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:53<00:00, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9301767\n",
      "Final Test Accuracy: 0.9035928\n",
      "Final Train Loss: 0.20570038520652828\n",
      "Final Test Loss: 0.31050494423619024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[2]\n",
    "dl = PACS_dataloaders('vit',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ViTBase(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'vit')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sketch Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:53<00:00, 37.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9792147\n",
      "Final Test Accuracy: 0.64520234\n",
      "Final Train Loss: 0.08793889044931061\n",
      "Final Test Loss: 1.0568840080691921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[3]\n",
    "dl = PACS_dataloaders('vit',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = ViTBase(n_classes=7)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'vit')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"PACS_vit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLIP \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['art_painting', 'cartoon','photo','sketch'] \n",
    "results = {domain:{} for domain in domains}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Art Painting Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\PCF\\.conda\\envs\\SProj\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\PCF\\.conda\\envs\\SProj\\Lib\\site-packages\\timm\\models\\vision_transformer.py:92: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  x = F.scaled_dot_product_attention(\n",
      "100%|██████████| 3/3 [01:04<00:00, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9499559\n",
      "Final Test Accuracy: 0.859375\n",
      "Final Train Loss: 1.7572492109199884\n",
      "Final Test Loss: 6.578734873794019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[0]\n",
    "dl = PACS_dataloaders('clip',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype,data=\"pacs\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = CLIPModel(emb_dim=256)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'clip')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cartoon Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "test_domain = domains[1]\n",
    "dl = PACS_dataloaders('clip',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype,data=\"pacs\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = CLIPModel(emb_dim=256)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'clip')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Photo Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:54<00:00, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.9558285\n",
      "Final Test Accuracy: 0.9664671\n",
      "Final Train Loss: 1.5918509413470607\n",
      "Final Test Loss: 1.7915605233515797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[2]\n",
    "dl = PACS_dataloaders('clip',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype,data=\"pacs\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = CLIPModel(emb_dim=256)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'clip')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sketch Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:54<00:00, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Accuracy: 0.950495\n",
      "Final Test Accuracy: 0.70043266\n",
      "Final Train Loss: 1.4205373021235699\n",
      "Final Test Loss: 22.70512153256324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_domain = domains[3]\n",
    "dl = PACS_dataloaders('clip',test_domain,BATCH_SIZE,True)\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype,data=\"pacs\")\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"pacs\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "model = CLIPModel(emb_dim=256)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,model,loss_func,optimizer,device,'clip')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])\n",
    "\n",
    "results[test_domain] = {\"Final Train Accuracy\":tr[\"Accuracy\"][-1],\n",
    "                        \"Final Train Loss\":tr[\"Loss\"][-1],\n",
    "                        \"Final Test Accuracy\":ts[\"Accuracy\"][-1],\n",
    "                        \"Final Test Loss\":ts[\"Loss\"][-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"PACS_clip.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
