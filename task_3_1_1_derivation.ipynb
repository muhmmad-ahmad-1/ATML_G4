{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given $$L_{DIST}(p,q) = - \\sum_{i=1}^{N} p_i log(q_i) $$ where $p_i$ = $\\frac{\\exp(\\frac{v_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{v_j}{T})}$ and \n",
    "$q_i$ = $\\frac{\\exp(\\frac{z_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})}$ and $z_i$,$v_i$, and $T$ denote the teacher's unsoftened logits, student's unsoftened logits, and the temperature respectively. \n",
    "\n",
    "Since $\\sigma(t) = \\frac{\\exp(\\frac{z_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})}$ we rewrite $p_i$ and $q_i$ as $\\sigma(\\frac{v_i}{T})$ and $\\sigma(\\frac{z_i}{T})$ for the sake of brevity.\n",
    "\n",
    "Then $$\\frac{\\partial L_{DIST}}{\\partial {z_i}} = - \\frac{\\partial }{\\partial {z_i}} \\sum_{k=1}^{N} \\sigma(\\frac{v_k}{T}) \\log(\\sigma(\\frac{z_k}{T}))$$\n",
    "$$ = - \\sum_{k=1}^{N} \\sigma(\\frac{v_k}{T}) \\frac{\\partial }{\\partial {z_i}}\\log(\\sigma(\\frac{z_k}{T})) $$\n",
    "\n",
    "Now, $$\\frac{\\partial }{\\partial {z_i}} \\log(\\sigma(\\frac{z_k}{T})) = \\frac{1}{\\sigma(\\frac{z_k}{T})} \\frac{\\partial }{\\partial {z_i}} \\sigma(\\frac{z_k}{T}) $$\n",
    "$$ = \\frac{1}{\\sigma(\\frac{z_k}{T})} \\frac{\\partial }{\\partial {z_i}} \\frac{\\exp(\\frac{z_k}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})}$$\n",
    "\n",
    "where $$ \\frac{\\partial }{\\partial {z_i}} {\\exp(\\frac{z_k}{T})} = \\frac{1}{T} \\exp(\\frac{z_k}{T}) \\delta_{ik} $$ and $$  \\delta_{ik} = \\begin{array}{cc} \\{ & \n",
    "    \\begin{array}{cc}\n",
    "      1 & i = k \\\\\n",
    "      0 & i \\neq k\n",
    "    \\end{array}\n",
    "\\end{array} $$\n",
    "\n",
    "Similarly, $$ \\frac{\\partial }{\\partial {z_i}} \\frac{\\exp(\\frac{z_k}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})}  = \\frac{1}{T}\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T}) \\delta_{ij} = \\frac{1}{T} \\exp(\\frac{z_i}{T})  $$\n",
    "\n",
    "Putting it all together, and using quotient rule, we have:\n",
    "$$ \\frac{\\partial }{\\partial {z_i}} \\frac{\\exp(\\frac{z_k}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})} = \\frac{1}{T} \\frac{\\exp(\\frac{z_k}{T})\\delta_{ik}\\sum_{i=1}^N \\exp(\\frac{z_j}{T}) - \\exp(\\frac{z_k}{T}) \\exp(\\frac{z_i}{T}) }{[\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})]^2}$$\n",
    "\n",
    "$$ = \\frac{\\exp(\\frac{z_k}{T})}{T \\sum_{i=1}^N \\exp(\\frac{z_j}{T})} \\Bigg[ \\frac{\\delta_{ik} \\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})} {\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})} -  \\frac{\\exp(\\frac{z_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})} \\Bigg] = \\sigma(\\frac{z_k}{T}) \\Bigg[\\delta_{ik} - \\sigma(\\frac{z_i}{T}) \\Bigg] \\times \\frac{1}{T}\n",
    "$$\n",
    "$$ \\rightarrow \\frac{\\partial }{\\partial {z_i}} \\log{(\\sigma{(\\frac{z_k}{T})})} = \\frac{(\\delta_{ik} - \\sigma(\\frac{z_i}{T}))}{T} $$\n",
    "\n",
    "$$ \\rightarrow \\frac{\\partial L_{DIST}}{\\partial {z_i}} = - \\frac{1}{T} \\sum_{k=1}^{N} \\frac{\\exp(\\frac{v_k}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{v_j}{T})} \\Bigg[\\delta_{ik} - \\frac{\\exp(\\frac{z_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})}  \\Bigg] $$\n",
    "\n",
    "Shifting back to p and q for now for ease in simplification:\n",
    "$$\\frac{\\partial L_{DIST}}{\\partial {z_i}} = - \\frac{1}{T} \\Bigg[ \\sum_{k=1}^{N} p_k \\delta_{ik} - \\sum_{k=1}^{N} p_k q_i \\Bigg] = - \\frac{1}{T} \\Bigg[ p_i  - q_i \\sum_{k=1}^{N} p_k  \\Bigg] $$\n",
    "Here we use the fact that $\\delta_{ik} = 0 $ when $i$ does not equal $k$ so only $p_i$ remains of the sum. Taking $q_i$ out as it is independent of the variable of summation, we have the sum of all probabilities $p_i$ (softened teacher logits) which must sum to 1.\n",
    "$$ \\rightarrow \\frac{\\partial L_{DIST}}{\\partial {z_i}} = - \\frac{1}{T} \\Big[ p_i - q_i \\Big] = \\frac{1}{T} \\Big[ q_i - p_i \\Big]$$\n",
    "\n",
    "By the Taylor Series Expansion for $\\exp(x)$ where for sufficiently small $x$ ($ x \\ll 1$):\n",
    "$$\\exp(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots = 1 + x + \\text{H.O.T.} \\approx 1 + x$$\n",
    "In the case where  $ v_k \\ll T$ and $ z_k \\ll T$  we can reasonably approximate $\\exp(\\frac{v_k}{T})$ as $1 + \\frac{v_k}{T}$ and $\\exp(\\frac{z_k}{T})$ as $1 + \\frac{z_k}{T}$. \n",
    "\n",
    "This approximation holds when the temperature is sufficiently high i.e. is an order of magnitude (or more) greater than the logits (teacher and/or student).\n",
    "\n",
    "Applying this approximation, we get:\n",
    "$$ \\frac{\\partial L_{DIST}}{\\partial {z_i}} \\approx \\frac{1}{T} \\Bigg[ \\frac{\\exp(\\frac{z_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{z_j}{T})} - \\frac{\\exp(\\frac{v_i}{T})}{\\sum_{j=1}^{N}\\exp(\\frac{v_j}{T})}  \\Bigg] = \\frac{1}{T} \\Bigg[ \\frac{(1+\\frac{z_i}{T})}{\\sum_{j=1}^{N}(1+\\frac{z_j}{T})} - \\frac{(1+\\frac{v_i}{T})}{\\sum_{j=1}^{N}(1+\\frac{v_j}{T})}  \\Bigg] = \\frac{1}{T} \\Bigg[ \\frac{(1+\\frac{z_i}{T})}{\\sum_{j=1}^{N}1+\\sum_{j=1}^{N} \\frac{z_j}{T} } - \\frac{(1+\\frac{v_i}{T})}{\\sum_{j=1}^{N}1+\\sum_{j=1}^{N}\\frac{v_j}{T}}  \\Bigg]$$\n",
    "\n",
    "$$ =  \\frac{1}{T} \\Bigg[ \\frac{(1+\\frac{z_i}{T})}{N+\\sum_{j=1}^{N} \\frac{z_j}{T} } - \\frac{(1+\\frac{v_i}{T})}{N+\\sum_{j=1}^{N}\\frac{v_j}{T}}  \\Bigg]$$\n",
    "\n",
    "Applying the assumption that logits are zero mean separately i.e. $\\sum_{j=1}^{N} z_j = \\sum_{j=1}^{N} v_j  = 0 $ implies that $\\sum_{j=1}^{N} \\frac{z_j}{T} = \\sum_{j=1}^{N} \\frac{v_j}{T} = 0$\n",
    "$$ \\frac{\\partial L_{DIST}}{\\partial {z_i}} \\approx \\frac{1}{T} \\Bigg[\\frac{\\frac{1+z_i}{T}}{N} - \\frac{\\frac{1+v_i}{T}}{N} \\Bigg] = \\frac{1}{T^2} \\Bigg[\\frac{z_i+T}{N} - \\frac{T+v_i}{N} \\Bigg] = \\frac{1}{T^2} \\Bigg[\\frac{z_i+T - T -v_i}{N} \\Bigg] = \\frac{1}{N T^2} \\Big(z_i-v_i\\Big)$$\n",
    "\n",
    "$$ \\implies \\frac{\\partial L_{DIST}}{\\partial {z_i}} \\approx \\frac{1}{N T^2} \\Big(z_i-v_i\\Big) $$ \n",
    "under the above mentioned assumptions.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
