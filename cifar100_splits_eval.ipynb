{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import ResNet50, ViTBase, CLIPModel\n",
    "from models.utils import train_step, eval_step, DataLoaders, CIFAR100_Splits,DataLoader\n",
    "from models.transforms import transforms_resnet,transforms_clip_vit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare all models for evaluation on concept shift through CIFAR100 Splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CIFAR10(root='data',transform=transforms_resnet,download=True)\n",
    "test = CIFAR10(root='data',transform=transforms_resnet,train=False,download=True)\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 3\n",
    "dl = DataLoaders(train,test,'resnet',BATCH_SIZE,True,'cifar10')\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "def train_and_eval(train_loader,test_loader,model,loss_fn,optimizer,device,modeltype):\n",
    "    tr_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "    ts_metric = {\"Accuracy\":[],\"Loss\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "        tr_loss, tr_acc = train_step(model,train_loader,loss_fn,optimizer,device,modeltype)\n",
    "        ts_loss, ts_acc = eval_step(model,test_loader,loss_fn,device,modeltype,data=\"cifar10\")\n",
    "\n",
    "        tr_metric[\"Accuracy\"].append(tr_acc)\n",
    "        tr_metric[\"Loss\"].append(tr_loss)\n",
    "\n",
    "        ts_metric[\"Accuracy\"].append(ts_acc)\n",
    "        ts_metric[\"Loss\"].append(ts_loss)\n",
    "    \n",
    "    return tr_metric, ts_metric\n",
    "\n",
    "resnet_model = ResNet50(n_classes=10)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet_model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,resnet_model,loss_func,optimizer,device,'resnet50')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CIFAR10(root='data',transform=transforms_clip_vit,download=True)\n",
    "test = CIFAR10(root='data',transform=transforms_resnet,train=False,download=True)\n",
    "dl = DataLoaders(train,test,'vit',BATCH_SIZE,True,'cifar10')\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "vit_model = ViTBase(n_classes=10)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(vit_model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,vit_model,loss_func,optimizer,device,'vit')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CIFAR10(root='data',download=True)\n",
    "test = CIFAR10(root='data',train=False,download=True)\n",
    "dl = DataLoaders(train,test,'clip',BATCH_SIZE,True,'cifar10')\n",
    "train_loader, test_loader = dl.get_loaders()\n",
    "\n",
    "clip_model = CLIPModel(256)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(clip_model.parameters())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "tr,ts = train_and_eval(train_loader,test_loader,clip_model,loss_func,optimizer,device,'clip')\n",
    "\n",
    "print(\"Final Train Accuracy:\",tr[\"Accuracy\"][-1])\n",
    "print(\"Final Test Accuracy:\",ts[\"Accuracy\"][-1])\n",
    "print(\"Final Train Loss:\",tr[\"Loss\"][-1])\n",
    "print(\"Final Test Loss:\",ts[\"Loss\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the CIFAR100 dataset and make the splits according to the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_datasets = {'resnet':[],'vit':[],'clip':[]}\n",
    "test = CIFAR100(root='data',train=False,download=True)\n",
    "\n",
    "for i in range(10):\n",
    "    for group in groups_datasets.keys():\n",
    "        groups_datasets[group].append(CIFAR100_Splits(test.data,test.targets,i,group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'resnet':{},'vit':{},'clip':{}}\n",
    "for group in groups_datasets.keys():\n",
    "        if group == 'resnet':\n",
    "                model = resnet_model\n",
    "        elif group == \"vit\":\n",
    "                model = vit_model\n",
    "        else:\n",
    "                model = clip_model\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        for dataset in groups_datasets[group]:\n",
    "                dl = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "                ts_loss, ts_acc = eval_step(model,dl,loss_func,device,group,data=\"cifar10\")\n",
    "                metrics[group].append(ts_acc)\n",
    "\n",
    "pd.DataFrame(metrics).to_csv('cifar100_splits_test_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_datasets = {'resnet':[],'vit':[],'clip':[]}\n",
    "train = CIFAR100(root='data',train=True,download=True)\n",
    "\n",
    "for i in range(10):\n",
    "    for group in groups_datasets.keys():\n",
    "        groups_datasets[group].append(CIFAR100_Splits(train.data,train.targets,i,group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'resnet':{},'vit':{},'clip':{}}\n",
    "for group in groups_datasets.keys():\n",
    "        if group == 'resnet':\n",
    "                model = resnet_model\n",
    "        elif group == \"vit\":\n",
    "                model = vit_model\n",
    "        else:\n",
    "                model = clip_model\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        for dataset in groups_datasets[group]:\n",
    "                dl = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "                ts_loss, ts_acc = eval_step(model,dl,loss_func,device,group,data=\"cifar10\")\n",
    "                metrics[group].append(ts_acc)\n",
    "\n",
    "pd.DataFrame(metrics).to_csv('cifar100_splits_train_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
